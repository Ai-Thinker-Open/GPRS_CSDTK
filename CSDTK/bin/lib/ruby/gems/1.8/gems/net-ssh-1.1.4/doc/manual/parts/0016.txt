To run multiple processes in parallel, you can access the channel API directly, setting up multiple channels and callbacks in order to process the output from the channel.

Suppose, for example, that you wanted to run multiple "tail" commands on various logs on the remote machine, combining them all into the output on the client. Something like the following would suffice:

{{{lang=ruby,number=true,caption=Running "tail" on multiple remote files
def do_tail( session, file )
  session.open_channel do |channel|
    channel.on_data do |ch, data|
      puts "[#{file}] -> #{data}"
    end
    channel.exec "tail -f #{file}"
  end
end

Net::SSH.start( 'host' ) do |session|
  do_tail session, "/var/log/messages"
  do_tail session, "/var/log/XFree86.0.log"
  do_tail session, "/var/log/tomcat/catalina.log"
  do_tail session, "/var/log/mysql/mysql.err"
  session.loop
end
}}}

As you can see, four different logs are tailed on four separate channels. Each channel registers an @on_data@ callback (which simply displays the data it recieves, together with the name of the log file it came from). The @exec@ method of the channel is then invoked, which simply sends the request to execute the process to the server, and then returns.

The @loop@ method then blocks while packets and processed and callbacks are invoked, completing the program.

This approach works fine for processing data coming from the server, and with a little work and coordination can work well for sending data _to_ the server as well, by calling the @send_data@ method of the channel at the appropriate times. However, it requires a bit of forethought, since you have to come up with a simple state machine to manage most interactive sessions, and many times that's more effort than it is worth.
